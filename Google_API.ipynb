{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79cf8d79",
   "metadata": {},
   "source": [
    "## Google Photos API - Download images from Google Photos using Python\n",
    "\n",
    "Using the Google Photos REST API you can download, upload and modify images stored in Google Photos.\n",
    "Just as a quick refresher, REST is an architectural style for application programming interfaces that allows interaction with RESTful web services. [Red20]\n",
    "\n",
    "Get request allow to retrieve database records, POST requests to create new records, PUT to update records and delete requests to delete one.\n",
    "\n",
    "To set up a simple little project that allows you to use Python to download images from Google Photos and then edit them, I describe in the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac8f7c-932d-486f-900b-9fe3fa178138",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create virtualenv and install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6927380f-c820-4ef4-8f32-e68cbf500709",
   "metadata": {},
   "source": [
    "1. Open the terminal and navigate to your working directory. The folder structure of the repo includes the following directories:\n",
    "\n",
    "    * **credentials**: folder to store the credentials you need to authenticate your \"Python App\" to the Google Photos Library\n",
    "    * **media_items_list**: every time the script runs, I want to save a .csv file with all Google Photos media items and the corresponding metadata uploaded in the defined time period\n",
    "    * **downloads**: storing downloaded images from Google Photos\n",
    "\n",
    "\n",
    "2. Create a virtual environment `python3 -m venv venv`, activate it `. ./venv/bin/activate` and install requirements `pip install -r requirements.txt`\n",
    "\n",
    "3. Install ipykernel which provides the IPython kernel for Jupyter: `pip install ipykernel` and add your virtual environment to Jupyter: `python -m ipykernel install --user --name=venv` \n",
    "\n",
    "    You can check the installation by navigating to /Users/<user>/Library/Jupyter/kernels. There should be a new directory called 'venv'. In the folder you can find the file 'kernel.json', which contains the path for the used python installation is defined.\n",
    "\n",
    "4. Start jupyter notebook or jupyter lab: `jupyter lab .` and select the just created environment \"venv\" as Kernel\n",
    "\n",
    "![](read_me_img/select_kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5434000b-35ff-4aa2-a8b8-cc9a26f548d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enable Google API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa3746-d4a0-4795-8e5a-226490d6e554",
   "metadata": {},
   "source": [
    "5. Enable Google Photos API Service\n",
    "\n",
    "   1. Go to the Google API Console [https://console.cloud.google.com/](https://console.cloud.google.com/). \n",
    "   2. From the menu bar, select a project or create a new project.\n",
    "      ![](read_me_img/gifs/create_new_project_speed.gif)\n",
    "   3. To open the Google API Library, from the Navigation menu, select APIs & Services > Library. \n",
    "   4. Search for \"Google Photos Library API\". Select the correct result and click \"enable\". If its already enabled, click \"manage\"\n",
    "   ![](read_me_img/gifs/enable_api_speed.gif)\n",
    "   5. Afterwards it will forward you to the \"Photos API/Service details\" page (https://console.cloud.google.com/apis/credentials)\n",
    "\n",
    "\n",
    "6. Configure \"OAuth consent screen\" ([Source](https://stackoverflow.com/questions/65184355/error-403-access-denied-from-google-authentication-web-api-despite-google-acc))\n",
    "\n",
    "   1. Go back to the Photos API Service details page and click on \"[OAuth consent screen](https://console.cloud.google.com/apis/credentials/consent)\" on the left side (below \"Credentials\") \n",
    "   2. Add a Test user: Use the email of the account you want to use for testing the API call\n",
    "<br>\n",
    "   \n",
    "    ![](read_me_img/add_test_user.png)<br>\n",
    "\n",
    "7. Create API/OAuth credentials\n",
    "\n",
    "   1. On the left side at the Google Photos API Service page click on Credentials\n",
    "   2. Click on \"Create Credentials\" and create a OAuth client ID\n",
    "   3. As application type I am choosing \"Desktop app\" and give your client you want to use to call the API a name\n",
    "   4. Download the JSON file to the created credentials, rename it to \"client_secret.json\" and save it in the folder \"credentials\"\n",
    "    ![](read_me_img/gifs/create_credentials_speed.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb459754-dd88-4049-aa06-a200ae0eb5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google_API.ipynb    \u001b[34mcredentials\u001b[m\u001b[m         \u001b[34mread_me_img\u001b[m\u001b[m\n",
      "LICENSE             \u001b[31mexecute_notebook.sh\u001b[m\u001b[m requirements.txt\n",
      "README.md           \u001b[34mmedia_items_list\u001b[m\u001b[m    \u001b[34mvenv_test\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290cacec-9573-488d-89a2-67bb22814d69",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install and import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a7c7c7-9d39-4b7e-842d-5dadc7a79e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt \n",
    "#saves the output to variable capt, to print output capt.stdout, capt.stderr\n",
    "!pip install -r \"requirements.txt\"\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85475dc1-1cb4-466a-88a7-2a756faa747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dominikpolzer/Documents/repos/repos_test/google-photos-api/venv_test/bin/python\n",
      "/Users/dominikpolzer/Documents/repos/repos_test/google-photos-api/venv_test/bin/pip\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!which pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498c8c38-d525-462d-b3e6-a16b9da9c7a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use the Google Photo Library API for the first time:\n",
    "\n",
    "The following section shows how to use OAuth Credentials for authentication with the Google Library API. The code section below covers the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d724f-c302-4d5f-b3be-9341a4a0fc84",
   "metadata": {},
   "source": [
    "8. Create a service for the first time:\n",
    "\n",
    "    1. Initialize GooglePhotosApi `google_photos_api = GooglePhotosApi()`\n",
    "\n",
    "    2. Create Service using the `client_secret.json` file: `service = google_photos_api.create_service()`\n",
    "        \n",
    "        \n",
    "       <b>Calling the API for the first time:</b>\n",
    "       1. Google will ask you if you want to grant the App the required permissions you defined with the scope:\n",
    "       ![](read_me_img/sign_in_google_acc.png)\n",
    "       2. Since its just a test app at the moment, Google will make you aware of that > Click on \"Continue\"\n",
    "       3. Once you granted the app the required permissions, you will see a \"token_......pickle\" file created in the folder \"credentials\". This token file will be used for future calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e55f6c-d7a8-4541-961e-b28a768eeec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from google_auth_oauthlib.flow import Flow, InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "#from googleapiclient.http import MediaFileUpload\n",
    "from google.auth.transport.requests import Request\n",
    "import requests\n",
    "\n",
    "class GooglePhotosApi:\n",
    "    def __init__(self,\n",
    "                 api_name = 'photoslibrary',\n",
    "                 client_secret_file= r'./credentials/client_secret.json',\n",
    "                 api_version = 'v1',\n",
    "                 scopes = ['https://www.googleapis.com/auth/photoslibrary']):\n",
    "        '''\n",
    "        Args:\n",
    "            client_secret_file: string, location where the requested credentials are saved\n",
    "            api_version: string, the version of the service\n",
    "            api_name: string, name of the api e.g.\"docs\",\"photoslibrary\",...\n",
    "            api_version: version of the api\n",
    "\n",
    "        Return:\n",
    "            service:\n",
    "        '''\n",
    "\n",
    "        self.api_name = api_name\n",
    "        self.client_secret_file = client_secret_file\n",
    "        self.api_version = api_version\n",
    "        self.scopes = scopes\n",
    "        self.cred_pickle_file = f'./credentials/token_{self.api_name}_{self.api_version}.pickle'\n",
    "\n",
    "        self.cred = None\n",
    "\n",
    "    def run_local_server(self):\n",
    "        # is checking if there is already a pickle file with relevant credentials\n",
    "        if os.path.exists(self.cred_pickle_file):\n",
    "            with open(self.cred_pickle_file, 'rb') as token:\n",
    "                self.cred = pickle.load(token)\n",
    "\n",
    "        # if there is no pickle file with stored credentials, create one using google_auth_oauthlib.flow\n",
    "        if not self.cred or not self.cred.valid:\n",
    "            if self.cred and self.cred.expired and self.cred.refresh_token:\n",
    "                self.cred.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(self.client_secret_file, self.scopes)\n",
    "                self.cred = flow.run_local_server()\n",
    "\n",
    "            with open(self.cred_pickle_file, 'wb') as token:\n",
    "                pickle.dump(self.cred, token)\n",
    "        \n",
    "        return self.cred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f0efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=36029187014-ukjpt1k03rmvp90vkn5me3ac40qfl5k5.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fphotoslibrary&state=67i1kJ16GkFanlIs8p4Vj9jALZ56uF&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "# initialize photos api and create service\n",
    "google_photos_api = GooglePhotosApi()\n",
    "creds = google_photos_api.run_local_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb37b37d-9c1c-4c88-9f4f-4f2eeefc3c3a",
   "metadata": {},
   "source": [
    "### Use pythons requests module and the token file to retrieve data from Google Photos\n",
    "\n",
    "9. Use requests python module to send http requests to the Media Items API\n",
    "\n",
    "    Sources:\n",
    "    * https://stackoverflow.com/questions/56294506/mediaitems-search-next-returns-400\n",
    "    * https://developers.google.com/photos/library/reference/rest/v1/mediaItems/search?apix_params=%7B%22resource%22%3A%7B%22filters%22%3A%7B%22dateFilter%22%3A%7B%22dates%22%3A%5B%7B%22day%22%3A1%2C%22month%22%3A1%2C%22year%22%3A2022%7D%5D%7D%7D%7D%7D\n",
    "    \n",
    "    <br>\n",
    "    Send a post request to the media API to get a list with all items. Since the API return is limited to 100 items, the search is narrowed down to one day. With this, the call would only have a problem if more than 100 images were made/uploaded in one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27ee5847-923b-40f1-87cd-4b935dbd328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def get_response_from_medium_api(year, month, day):\n",
    "    url = 'https://photoslibrary.googleapis.com/v1/mediaItems:search'\n",
    "    payload = {\n",
    "                  \"filters\": {\n",
    "                    \"dateFilter\": {\n",
    "                      \"dates\": [\n",
    "                        {\n",
    "                          \"day\": day,\n",
    "                          \"month\": month,\n",
    "                          \"year\": year\n",
    "                        }\n",
    "                      ]\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "    headers = {\n",
    "        'content-type': 'application/json',\n",
    "        'Authorization': 'Bearer {}'.format(creds.token)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        res = requests.request(\"POST\", url, data=json.dumps(payload), headers=headers)\n",
    "    except:\n",
    "        print('Request error') \n",
    "    \n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a38726-10aa-47d8-9f57-4d575ce57193",
   "metadata": {},
   "source": [
    "Use the response of the API to write the results and required metadata into a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd790ac-1a44-4f79-afb9-1d6621c3f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_media_items(year, month, day, media_items_df):\n",
    "    '''\n",
    "    Args:\n",
    "        year, month, day: day for the filter of the API call \n",
    "        media_items_df: existing data frame with all find media items so far\n",
    "    Return:\n",
    "        media_items_df: media items data frame extended by the articles found for the specified tag\n",
    "        items_df: media items uploaded on specified date\n",
    "    '''\n",
    "\n",
    "    items_list_df = pd.DataFrame()\n",
    "    \n",
    "    # create request for specified date\n",
    "    response = get_response_from_medium_api(year, month, day)\n",
    "\n",
    "    try:\n",
    "        for item in response.json()['mediaItems']:\n",
    "            items_df = pd.DataFrame(item)\n",
    "            items_df = items_df.rename(columns={\"mediaMetadata\": \"creationTime\"})\n",
    "            items_df.set_index('creationTime')\n",
    "            items_df = items_df[items_df.index == 'creationTime']\n",
    "\n",
    "            #append the existing media_items data frame\n",
    "            items_list_df = pd.concat([items_list_df, items_df])\n",
    "            media_items_df = pd.concat([media_items_df, items_df])\n",
    "    \n",
    "    except:\n",
    "        print(response.text)\n",
    "\n",
    "    return(items_list_df, media_items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc1dda-4145-4c84-94ac-f8b634f794cd",
   "metadata": {},
   "source": [
    "## Use the defined functions to download media items from Google Photos\n",
    "\n",
    "1. Create a list with all files already downloaded to the /downloads/ folder\n",
    "2. Define a list of all dates from start date to end date (today)\n",
    "3. Execute the API call for all dates to get a list with all media items. API returns:\n",
    "    * **id**\n",
    "    * **filename**\n",
    "    * **baseUrl**: Base URLs within the Google Photos Library API allow you to access the bytes of the media items. They are valid for 60 minutes. (https://developers.google.com/photos/library/guides/access-media-items)\n",
    "\n",
    "\n",
    "4. Compare list of media items with files downloaded in /downloads/ with media items in Google Photos, to download items which are not downloaded yet. You can now use the baseUrl and the python requests module to send a get request for each media item.\n",
    "5. Save a list as with all media items as .csv in /media_items_list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cadce4a-cb1c-4fb4-affb-3eb40ac7efbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './downloads'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Images should only be downloaded if they are not already available in downloads\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Herefor the following code snippet, creates a list with all filenames in the /downloads/ folder\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m files_list \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./downloads\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m files_list_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(files_list)\n\u001b[1;32m      9\u001b[0m files_list_df \u001b[38;5;241m=\u001b[39m files_list_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './downloads'"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from datetime import date, timedelta, datetime\n",
    "import requests\n",
    "\n",
    "# Images should only be downloaded if they are not already available in downloads\n",
    "# Herefor the following code snippet, creates a list with all filenames in the /downloads/ folder\n",
    "files_list = os.listdir(r'./downloads')\n",
    "files_list_df = pd.DataFrame(files_list)\n",
    "files_list_df = files_list_df.rename(columns={0: \"filename\"})\n",
    "files_list_df.head(2)\n",
    "\n",
    "# create a list with all dates between start date and today\n",
    "sdate = date(2021,4,16)   # start date\n",
    "edate = date.today()\n",
    "date_list = pandas.date_range(sdate,edate-timedelta(days=1),freq='d')\n",
    "print(date_list)\n",
    "\n",
    "media_items_df = pd.DataFrame()\n",
    "\n",
    "for date in date_list:\n",
    "    \n",
    "    # get a list with all media items for specified date (year, month, day)\n",
    "    items_df, media_items_df = list_of_media_items(year = date.year, month = date.month, day = date.day, media_items_df = media_items_df)\n",
    "\n",
    "    if len(items_df) > 0:\n",
    "        # full outer join of items_df and files_list_df, the result is a list of items of the given \n",
    "        #day that have not been downloaded yet\n",
    "        items_not_yet_downloaded_df = pd.merge(items_df, files_list_df,on='filename',how='left')\n",
    "        items_not_yet_downloaded_df.head(2)\n",
    "\n",
    "        # download all items in items_not_yet_downloaded\n",
    "        for index, item in items_not_yet_downloaded_df.iterrows():\n",
    "            url = item.baseUrl\n",
    "            response = requests.get(url)\n",
    "\n",
    "            file_name = item.filename\n",
    "            destination_folder = './downloads/'\n",
    "\n",
    "            with open(os.path.join(destination_folder, file_name), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "                f.close()\n",
    "                \n",
    "        print(f'Downloaded items found for date: {date.year} / {date.month} / {date.day}')\n",
    "    else:\n",
    "        print(f'No media items found for date: {date.year} / {date.month} / {date.day}')\n",
    "            \n",
    "#save a list of all media items to a csv file\n",
    "current_datetime = str(datetime.now())\n",
    "filename = f'item-list-{current_datetime}.csv'\n",
    "\n",
    "#save a list with all items in specified time frame\n",
    "media_items_df.to_csv(f'./media_items_list/{filename}', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662b7c2-04ee-42e9-9b73-a3a1bfbcc97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"update readme\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda36fbe-e8c3-4753-b90c-89410daf8aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test_image_download",
   "language": "python",
   "name": "venv_test_image_download"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
